{"cells":[{"cell_type":"code","source":["# %pip install azure-ai-textanalytics\n","# %pip install azure-search-documents\n","# %pip install openai --upgrade\n","\n","# %pip install langchain\n","# %pip install PyPDF2\n","# %pip install tiktoken"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"33dc6091-e0c6-403b-bb1e-935336803c57"},{"cell_type":"code","source":["#Get Azure Key Vault Client\n","key_vault_name = 'kv_to-be-replaced'\n","\n","index_name = 'draftsindex'\n","file_system_client = \"data\"\n","directory = 'demodata/completed_grants' \n","csv_file_name = 'completed_grants.csv'\n","\n","num_pages = 10"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"322036a9-c396-4207-b56c-e26b8386696b","statement_id":31,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-21T07:47:12.0343896Z","session_start_time":null,"execution_start_time":"2024-03-21T07:47:44.515372Z","execution_finish_time":"2024-03-21T07:47:44.7743301Z","parent_msg_id":"100ccb09-fb1e-4227-87e6-3970f666ca75"},"text/plain":"StatementMeta(, 322036a9-c396-4207-b56c-e26b8386696b, 31, Finished, Available)"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"02278b5f-06e2-4f1d-a11a-7030c696b06d"},{"cell_type":"code","source":["from trident_token_library_wrapper import PyTridentTokenLibrary as tl\n","\n","def get_secrets_from_kv(kv_name, secret_name):\n","\n","    access_token = mssparkutils.credentials.getToken(\"keyvault\")\n","    kv_endpoint = f'https://{kv_name}.vault.azure.net/'\n","    return(tl.get_secret_with_token(kv_endpoint,secret_name,access_token))\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"322036a9-c396-4207-b56c-e26b8386696b","statement_id":32,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-21T07:47:12.3391254Z","session_start_time":null,"execution_start_time":"2024-03-21T07:47:45.2247551Z","execution_finish_time":"2024-03-21T07:47:45.4497045Z","parent_msg_id":"6a58dcfb-72f8-4850-9442-6d66bf26ef90"},"text/plain":"StatementMeta(, 322036a9-c396-4207-b56c-e26b8386696b, 32, Finished, Available)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c6fe9e75-4932-47e5-a40a-5be9ecf4cd6c"},{"cell_type":"code","source":["# Import required libraries  \n","import os  \n","import json  \n","import openai\n","\n","import os  \n","from azure.core.credentials import AzureKeyCredential  \n","from azure.ai.textanalytics import TextAnalyticsClient  \n","\n","from azure.core.credentials import AzureKeyCredential  \n","from azure.search.documents import SearchClient, SearchIndexingBufferedSender  \n","from azure.search.documents.indexes import SearchIndexClient  \n","from azure.search.documents.models import (\n","    QueryAnswerType,\n","    QueryCaptionType,\n","    QueryCaptionResult,\n","    QueryAnswerResult,\n","    SemanticErrorMode,\n","    SemanticErrorReason,\n","    SemanticSearchResultsType,\n","    QueryType,\n","    VectorizedQuery,\n","    VectorQuery,\n","    VectorFilterMode,    \n",")\n","from azure.search.documents.indexes.models import (  \n","    ExhaustiveKnnAlgorithmConfiguration,\n","    ExhaustiveKnnParameters,\n","    SearchIndex,  \n","    SearchField,  \n","    SearchFieldDataType,  \n","    SimpleField,  \n","    SearchableField,  \n","    SearchIndex,  \n","    SemanticConfiguration,  \n","    SemanticPrioritizedFields,\n","    SemanticField,  \n","    SearchField,  \n","    SemanticSearch,\n","    VectorSearch,  \n","    HnswAlgorithmConfiguration,\n","    HnswParameters,  \n","    VectorSearch,\n","    VectorSearchAlgorithmConfiguration,\n","    VectorSearchAlgorithmKind,\n","    VectorSearchProfile,\n","    SearchIndex,\n","    SearchField,\n","    SearchFieldDataType,\n","    SimpleField,\n","    SearchableField,\n","    VectorSearch,\n","    ExhaustiveKnnParameters,\n","    SearchIndex,  \n","    SearchField,  \n","    SearchFieldDataType,  \n","    SimpleField,  \n","    SearchableField,  \n","    SearchIndex,  \n","    SemanticConfiguration,  \n","    SemanticField,  \n","    SearchField,  \n","    VectorSearch,  \n","    HnswParameters,  \n","    VectorSearch,\n","    VectorSearchAlgorithmKind,\n","    VectorSearchAlgorithmMetric,\n","    VectorSearchProfile,\n",")  \n","search_endpoint =  get_secrets_from_kv(key_vault_name,\"AZURE-SEARCH-SERVICE-ENDPOINT\")\n","search_key =  get_secrets_from_kv(key_vault_name,\"AZURE-SEARCH-ADMIN-KEY\")\n","\n","openai.api_type = get_secrets_from_kv(key_vault_name,\"OPENAI-API-TYPE\")\n","openai.api_key  = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-API-KEY\")\n","openai.api_base = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-ENDPOINT\")\n","openai.api_version = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-API-VERSION\")\n","\n","openai_api_type = get_secrets_from_kv(key_vault_name,\"OPENAI-API-TYPE\")\n","openai_api_key  = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-API-KEY\")\n","openai_api_base = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-ENDPOINT\")\n","openai_api_version = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-API-VERSION\")\n","\n","# Set up your Azure Text Analytics service and credentials  \n","COG_SERVICES_NAME = get_secrets_from_kv(key_vault_name,\"COG-SERVICES-NAME\")\n","COG_SERVICES_ENDPOINT = get_secrets_from_kv(key_vault_name,\"COG-SERVICES-ENDPOINT\")\n","COG_SERVICES_KEY = get_secrets_from_kv(key_vault_name,\"COG-SERVICES-KEY\")\n","\n","cog_services_credential = AzureKeyCredential(COG_SERVICES_KEY)  \n","\n","# Create a TextAnalyticsClient using your endpoint and credentials  \n","cog_services_client = TextAnalyticsClient(endpoint=COG_SERVICES_ENDPOINT, credential=cog_services_credential)  \n","\n","def get_named_entities(cog_services_client,input_text): \n","    # Call the named entity recognition API to extract named entities from your text  \n","    result = cog_services_client.recognize_entities(documents=[input_text])  \n","    \n","    # return the named entities for each document \n","    # full list of categories #https://learn.microsoft.com/en-us/azure/ai-services/language-service/named-entity-recognition/concepts/named-entity-categories?tabs=ga-api \n","\n","    Person = [] \n","    Location = []\n","    Organization = [] \n","    DateTime = []\n","    URL = [] \n","    Email = []\n","    PersonType = []\n","    Event = []\n","    Quantity = []\n","\n","    for idx, doc in enumerate(result):\n","        if not doc.is_error:\n","            for entity in doc.entities: \n","                if entity.category == \"DateTime\":\n","                    DateTime.append(entity.text)\n","                elif entity.category == \"Person\":\n","                    Person.append(entity.text)\n","                elif entity.category == \"Location\":\n","                    Location.append(entity.text)\n","                elif entity.category == \"Organization\":\n","                    Organization.append(entity.text)\n","                elif entity.category == \"URL\":\n","                    URL.append(entity.text)\n","                elif entity.category == \"Email\":\n","                    Email.append(entity.text)\n","                elif entity.category == \"PersonType\":\n","                    PersonType.append(entity.text)\n","                elif entity.category == \"Event\":\n","                    Event.append(entity.text)\n","                elif entity.category == \"Quantity\":\n","                    Quantity.append(entity.text)\n","\n","        else:  \n","            print(\"  Error: {}\".format(doc.error.message)) \n","    return(list(set(DateTime)),list(set(Person)),list(set(Location)),list(set(Organization)),list(set(URL)),list(set(Email)),list(set(PersonType)),list(set(Event)),list(set(Quantity)))\n","    \n","\n","from openai import AzureOpenAI\n","\n","# Function: Get Embeddings\n","def get_embeddings(text: str,openai_api_base,openai_api_version,openai_api_key):\n","    model_id = \"text-embedding-ada-002\"\n","    client = AzureOpenAI(\n","        api_version=openai_api_version,\n","        azure_endpoint=openai_api_base,\n","        api_key = openai_api_key\n","    )\n","    \n","    embedding = client.embeddings.create(input=text, model=model_id).data[0].embedding\n","\n","    return embedding\n","\n","from langchain.text_splitter import MarkdownTextSplitter, RecursiveCharacterTextSplitter, PythonCodeTextSplitter\n","import tiktoken\n","\n","import re\n","\n","def clean_spaces_with_regex(text):\n","    # Use a regular expression to replace multiple spaces with a single space\n","    cleaned_text = re.sub(r'\\s+', ' ', text)\n","    # Use a regular expression to replace consecutive dots with a single dot\n","    cleaned_text = re.sub(r'\\.{2,}', '.', cleaned_text)\n","    return cleaned_text\n","\n","def estimate_tokens(text):\n","    GPT2_TOKENIZER = tiktoken.get_encoding(\"gpt2\")\n","    return(len(GPT2_TOKENIZER.encode(text)))\n","\n","def chunk_data(text):\n","    text = clean_spaces_with_regex(text)\n","    SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n","    WORDS_BREAKS = ['\\n', '\\t', '}', '{', ']', '[', ')', '(', ' ', ':', ';', ',']\n","    num_tokens = 1024 #500\n","    min_chunk_size = 10\n","    token_overlap = 0\n","\n","    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(separators=SENTENCE_ENDINGS + WORDS_BREAKS,chunk_size=num_tokens, chunk_overlap=token_overlap)\n","\n","    return(splitter.split_text(text))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"322036a9-c396-4207-b56c-e26b8386696b","statement_id":33,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-21T07:47:12.97809Z","session_start_time":null,"execution_start_time":"2024-03-21T07:47:45.9032972Z","execution_finish_time":"2024-03-21T07:47:53.8315511Z","parent_msg_id":"f044815f-c238-4520-8495-52a9e631c08c"},"text/plain":"StatementMeta(, 322036a9-c396-4207-b56c-e26b8386696b, 33, Finished, Available)"},"metadata":{}}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c75f837e-c9ef-4ff3-8183-8e61dbe1cf76"},{"cell_type":"code","source":["# Create the search index\n","search_credential = AzureKeyCredential(search_key)\n","\n","index_client = SearchIndexClient(\n","    endpoint=search_endpoint, credential=search_credential)\n","\n","fields = [\n","    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n","    SearchableField(name=\"chunk_id\", type=SearchFieldDataType.String),\n","    SearchableField(name=\"document_id\", type=SearchFieldDataType.String),\n","    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n","    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n","    SearchableField(name=\"sourceurl\", type=SearchFieldDataType.String),\n","    SearchableField(name=\"publicurl\", type=SearchFieldDataType.String),\n","    SimpleField(name=\"dateTime\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"Person\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"Location\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"Organization\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"URL\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"Email\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"PersonType\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"Event\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SimpleField(name=\"Quantity\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),Filterable=True,Sortable=True, Facetable=True),\n","    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n","                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n","    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n","                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n","]\n","\n","# Configure the vector search configuration  \n","vector_search = VectorSearch(\n","    algorithms=[\n","        HnswAlgorithmConfiguration(\n","            name=\"myHnsw\",\n","            kind=VectorSearchAlgorithmKind.HNSW,\n","            parameters=HnswParameters(\n","                m=4,\n","                ef_construction=400,\n","                ef_search=500,\n","                metric=VectorSearchAlgorithmMetric.COSINE\n","            )\n","        ),\n","        ExhaustiveKnnAlgorithmConfiguration(\n","            name=\"myExhaustiveKnn\",\n","            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n","            parameters=ExhaustiveKnnParameters(\n","                metric=VectorSearchAlgorithmMetric.COSINE\n","            )\n","        )\n","    ],\n","    profiles=[\n","        VectorSearchProfile(\n","            name=\"myHnswProfile\",\n","            algorithm_configuration_name=\"myHnsw\",\n","        ),\n","        VectorSearchProfile(\n","            name=\"myExhaustiveKnnProfile\",\n","            algorithm_configuration_name=\"myExhaustiveKnn\",\n","        )\n","    ]\n",")\n","\n","semantic_config = SemanticConfiguration(\n","    name=\"my-semantic-config\",\n","    prioritized_fields=SemanticPrioritizedFields(\n","        title_field=SemanticField(field_name=\"title\"),\n","        content_fields=[SemanticField(field_name=\"content\")]\n","    )\n",")\n","\n","# Create the semantic settings with the configuration\n","semantic_search = SemanticSearch(configurations=[semantic_config])\n","\n","# Create the drafts search index with the semantic settings\n","index = SearchIndex(name=index_name, fields=fields,\n","                    vector_search=vector_search, semantic_search=semantic_search)\n","\n","result = index_client.create_or_update_index(index)\n","print(f' {result.name} created')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"322036a9-c396-4207-b56c-e26b8386696b","statement_id":34,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-21T07:47:13.5958231Z","session_start_time":null,"execution_start_time":"2024-03-21T07:47:54.2872856Z","execution_finish_time":"2024-03-21T07:47:55.0742836Z","parent_msg_id":"2548974c-36f5-4eab-a694-b2f7076ff7c0"},"text/plain":"StatementMeta(, 322036a9-c396-4207-b56c-e26b8386696b, 34, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" draftsindex created\n"]}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"900907a3-5498-4779-b3cc-40cb00dc86ca"},{"cell_type":"code","source":["# add documents to the index\n","\n","import PyPDF2  \n","import base64\n","import time\n","import pandas as pd\n","\n","account_name = get_secrets_from_kv(key_vault_name, \"ADLS-ACCOUNT-NAME\")\n","path_name = 'Files/' + account_name + '/' + directory + '/pdfs'\n","paths = mssparkutils.fs.ls(path_name)\n","\n","search_credential = AzureKeyCredential(search_key)\n","client = SearchClient(search_endpoint, index_name, search_credential)\n","\n","index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n","\n","metadata_filepath = 'Files/' + account_name + '/' + directory + '/metadata/' + csv_file_name\n","df_metadata = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"multiLine\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").load(metadata_filepath).toPandas()\n","\n","docs = []\n","num_pdfs = 0\n","counter = 0\n","for path in paths:\n","    num_pdfs += 1\n","    pdf_file_path = '/lakehouse/default/Files/' + account_name + '/' + directory + '/pdfs/' + path.name\n","    pdf_reader = PyPDF2.PdfReader(pdf_file_path)\n","    filename = path.name.split('/')[-1]\n","    document_id = filename.replace('.pdf','')\n","\n","    df_file_metadata = df_metadata[df_metadata['grant_id']==document_id].iloc[0]\n","   \n","    text = \"\" \n","\n","    n = num_pages #len(pdf_reader.pages)\n","    if len(pdf_reader.pages) < n:\n","        n = len(pdf_reader.pages)\n","    for page_num in range(n):\n","\n","        public_url = df_file_metadata['publicurl'] + '#page=' + str(page_num) \n","        page = pdf_reader.pages[page_num]\n","        text = page.extract_text()         \n","        \n","        chunks = chunk_data(text)\n","        chunk_num = 0\n","        for chunk in chunks:\n","            chunk_num += 1\n","            d = {\n","                \"chunk_id\" : path.name.split('/')[-1] + '_' + str(page_num).zfill(2) +  '_' + str(chunk_num).zfill(2),\n","                \"document_id\": str(df_file_metadata['grant_id']),\n","                 \"content\": chunk,       \n","                 \"title\": df_file_metadata['title']\n","                }\n","\n","            d[\"dateTime\"],d[\"Person\"],d[\"Location\"],d[\"Organization\"],d[\"URL\"],d[\"Email\"],d[\"PersonType\"],d[\"Event\"],d[\"Quantity\"] = get_named_entities(cog_services_client,d[\"content\"])\n","\n","            counter += 1\n","\n","            try:\n","                v_titleVector = get_embeddings(d[\"title\"],openai_api_base,openai_api_version,openai_api_key)\n","            except:\n","                time.sleep(30)\n","                v_titleVector = get_embeddings(d[\"title\"],openai_api_base,openai_api_version,openai_api_key)\n","            \n","            try:\n","                v_contentVector = get_embeddings(d[\"content\"],openai_api_base,openai_api_version,openai_api_key)\n","            except:\n","                time.sleep(30)\n","                v_contentVector = get_embeddings(d[\"content\"],openai_api_base,openai_api_version,openai_api_key)\n","\n","\n","            docs.append(\n","            {\n","                    \"id\": base64.urlsafe_b64encode(bytes(d[\"chunk_id\"], encoding='utf-8')).decode('utf-8'),\n","                    \"chunk_id\": d[\"chunk_id\"],\n","                    \"document_id\": d[\"document_id\"],\n","                    \"title\": d[\"title\"],\n","                    \"content\": d[\"content\"],\n","                    \"sourceurl\": path.name.split('/')[-1], \n","                    \"publicurl\": public_url,\n","                    \"dateTime\": d[\"dateTime\"],\n","                    \"Person\": d[\"Person\"],\n","                    \"Location\": d[\"Location\"],\n","                    \"Organization\": d[\"Organization\"],\n","                    \"URL\": d[\"URL\"],\n","                    \"Email\": d[\"Email\"],\n","                    \"PersonType\": d[\"PersonType\"],\n","                    \"Event\": d[\"Event\"],\n","                    \"Quantity\": d[\"Quantity\"],\n","                    \"titleVector\": v_titleVector,\n","                    \"contentVector\": v_contentVector\n","            }\n","            )\n","            \n","            if counter % 10 == 0:\n","                result = client.upload_documents(documents=docs)\n","                docs = []\n","                print(f' {str(counter)} uploaded')\n","\n","#upload the last batch\n","if docs != []:\n","    client.upload_documents(documents=docs)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"322036a9-c396-4207-b56c-e26b8386696b","statement_id":35,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-21T07:47:14.4201398Z","session_start_time":null,"execution_start_time":"2024-03-21T07:47:55.5161717Z","execution_finish_time":"2024-03-21T07:48:14.0498106Z","parent_msg_id":"d983afb4-909f-4f67-ad8a-331d5b093d04"},"text/plain":"StatementMeta(, 322036a9-c396-4207-b56c-e26b8386696b, 35, Finished, Available)"},"metadata":{}}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"255e0a09-150e-495c-a412-377fea573760"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"12c0394e-b329-4040-9f9f-6bcc4e09823b","default_lakehouse_name":"BYCLakehouse","default_lakehouse_workspace_id":"f5fe8dc7-ae07-4a98-af91-8933cd2e381c"}}},"nbformat":4,"nbformat_minor":5}